{"cells":[{"cell_type":"markdown","metadata":{"id":"gTddnVyjgJT4"},"source":["# Deep Learning - Preprocessing\n","\n","### *Facial age prediction - a SML Regression problem*"]},{"cell_type":"markdown","metadata":{"id":"Frw45Z4vgOGl"},"source":["# 1. References\n","\n","\n","1. What is the purpose of image preprocessing in deep learning?, [block article](https://www.isahit.com/blog/what-is-the-purpose-of-image-preprocessing-in-deep-learning#:~:text=Even%20though%20geometric%20transformations%20of,features%20crucial%20for%20subsequent%20processing)\n","2. Balancing an imbalanced dataset with keras image generator, [block article](https://stackoverflow.com/questions/41648129/balancing-an-imbalanced-dataset-with-keras-image-generator)\n","3. `tf.keras.utils.image_dataset_from_directory`, [link](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory)\n"]},{"cell_type":"markdown","metadata":{"id":"J38_qDoJgXVa"},"source":["# 2. Initial Treatment"]},{"cell_type":"markdown","metadata":{"id":"jXMU05G3gY3M"},"source":["## 2.1. Configurations and import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19636,"status":"ok","timestamp":1680919812436,"user":{"displayName":"Miguel Ramos","userId":"13440356191463058801"},"user_tz":-60},"id":"I5nq7OUrgIj2","outputId":"68911da8-81fd-4218-95ea-6338d942f1c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C3Jx7UrqggNZ"},"outputs":[],"source":["!pip install imageio --quiet\n","!pip install kaggle --quiet\n","!pip install imagehash --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JLxzI7GughVx"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import datasets\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","from tensorflow.keras import Sequential, layers, initializers, regularizers, optimizers, metrics\n","import imageio.v2 as imageio\n","from google.colab import files\n","\n","from sklearn.metrics import pairwise_distances\n","from sklearn.decomposition import PCA\n","from sklearn.ensemble import IsolationForest\n","\n","import os\n","import time\n","import shutil\n","import random \n","import zipfile\n","import math\n","from collections import defaultdict\n","import imagehash\n","import itertools\n","import pickle\n","\n","import gdown # To download zip file from URL\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from matplotlib.colors import ListedColormap\n","import seaborn as sns\n","\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"wrNGI0Y-gk_s"},"source":["## 2.2. Auxiliary functions\n","\n","Collection of all user defined functions in this notebook. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1BreDTw0giq5"},"outputs":[],"source":["def create_image_grid_per_group(image_groups, images_per_row, show_class=False):\n","  '''\n","  Creates a grid of images for each group of images in a dictionary.\n","\n","  Args:\n","  --\n","    image_groups (dict): A dictionary where the keys are group labels and the values are lists of paths to the images in each group.\n","    images_per_row (int): The number of images to display in each row of the grid.\n","    show_class (bool): Parameter to show or not the class of the image\n","\n","  Returns:\n","  --\n","    None. The resulting image grids are saved to .jpg files and displayed on screen.\n","  '''\n","\n","  for group_label, image_paths in image_groups.items():\n","    print(\"--------------------------------------------------------------------\")\n","    print(group_label)\n","    if show_class:\n","        groups_list = [path.split('/')[-2] for path in image_paths] \n","        print(groups_list)\n","    print(\"--------------------------------------------------------------------\")\n","    image_files = [f for f in image_paths if os.path.splitext(f)[1].lower() in ('.png', '.jpg', '.jpeg')]\n","\n","    img_sizes = [Image.open(f).size for f in image_files]\n","    max_width = max([size[0] for size in img_sizes])\n","    max_height = max([size[1] for size in img_sizes])\n","\n","    num_rows = math.ceil(len(image_files) / images_per_row)\n","    grid_size = (max_width * images_per_row, max_height * num_rows)\n","    grid_image = Image.new('RGB', grid_size, color='white')\n","\n","    for i, image_file in enumerate(image_files):\n","        img = Image.open(image_file)\n","\n","        x = (i % images_per_row) * max_width\n","        y = (i // images_per_row) * max_height\n","        grid_image.paste(img, (x, y))\n","\n","    grid_image.save(f'image_grid_{group_label}.jpg')\n","    grid_image.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tYP5Gd3hssAJ"},"outputs":[],"source":["def save_images(dataset, output_folder):\n","  '''\n","  Saves a set of images in a specified folder.\n","\n","  Args:\n","  --\n","  dataset (tf.data.Dataset): Output from the function image_dataset_from_dictionary().\n","  output_folder (str): Path to the folder where we want to store the images of the dataset.\n","\n","  Returns:\n","  --\n","    None. The images from the dataset are stored on the output_folder.\n","  '''\n","\n","    # Initialize timer\n","    t0 = time.time()\n","    \n","    i = 0\n","    print('Saving images for', output_folder.split('/')[-1])\n","    for file_path in dataset.file_paths:\n","        if i % 500 == 0:\n","            print('Saved', i, 'images')\n","        class_age = str(int(file_path.split('/')[-2]))\n","        file_name = file_path.split('/')[-1]\n","\n","        folder_path = os.path.join(output_folder, class_age)\n","        os.makedirs(folder_path, exist_ok=True)\n","\n","        image_path = os.path.join(folder_path, file_name)\n","        shutil.copy(file_path, image_path)\n","        i += 1\n","    print('Saved all images - Total', i)\n","    print(\"Saved in %0.3f seconds\" % (time.time() - t0))\n","    print(\"Waiting 5 minutes to sync all files in Drive\")\n","    time.sleep(60 * 5)"]},{"cell_type":"markdown","metadata":{"id":"Ab49NKGpgmbH"},"source":["## 2.3. Configuring paths and loading files\n","\n","Loading the generated files from exploration part."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"enBPUqJ2aGcT"},"outputs":[],"source":["# Define the path, where the dataset should be saved\n","vm_path = \"/content\"\n","path = \"/content/drive/MyDrive/FacialAgeProject/\"\n","\n","data_path = os.path.join(path, 'data')\n","metadata_path = os.path.join(path, 'metadata')\n","dataset_path = os.path.join(data_path, \"facial_age_dataset_unsplit/\")\n","\n","duplicated_path = os.path.join(metadata_path, 'ahash_duplicated_keys.pkl')\n","preprocessed_path = os.path.join(data_path, 'facial_age_dataset_preprocessed')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBXJEXLkg8ba"},"outputs":[],"source":["with (open(duplicated_path, \"rb\")) as openfile:\n","    duplicated_keys = pickle.load(openfile)\n","\n","duplicated_paths = [path for path_list in duplicated_keys.values() for path in path_list]"]},{"cell_type":"markdown","metadata":{"id":"FmeVLczOcvZ7"},"source":["# 3. Preprocessing\n","\n","Preprocessing is a crucial aspect of computer vision projects as it enhances the image quality and makes it appropriate for training deep learning models [1]. In our investigation, we discovered that our dataset is unbalanced, with a strong representation of images in the younger age groups, and a decreasing proportion of images for the older age groups. Additionally, we identified the presence of duplicates, some of which appear in groups of three or four. We need to take this into consideration during preprocessing, as we want all images and classes to be treated equally and not give undue importance to duplicates. After simplifying the set, we will split it into a temporary training set and the final test set to complete the process."]},{"cell_type":"markdown","metadata":{"id":"a0LcoXcCcon-"},"source":["## 3.1. Removing the duplicates from the main folder\n","\n","In terms of removing duplicates, we opted to remove the duplicates identified by the ahash method. We chose to use ahash instead of phash and geometric distance method because ahash was able to identify a greater number of duplicates. Additionally, as mentioned in the explore notebook, ahash is better suited for detecting near-duplicates in image sets that have not undergone significant transformations, which is applicable to our scenario. Despite the fact that some of the images identified as duplicates may not actually be duplicates, we decided to stick with ahash for what was previously explained. The drawback of this approach is that more single images will be deleted, but we don't consider this a problem as we have a substantial and well-represented dataset. Our next step will be to eliminate all pairs of duplicates, as well as groups of 3 and 4 duplicates, from our primary folder. As some of these duplicates have been assigned to different classes, we cannot know the actual age of the person, so we can't consider any of them. We will temporarily store these duplicates in a separate folder."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":302127,"status":"ok","timestamp":1680923103637,"user":{"displayName":"Miguel Ramos","userId":"13440356191463058801"},"user_tz":-60},"id":"OISrTMvarWX0","outputId":"1ca2bb2f-b8e4-46ee-b8da-4cb921d9826c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Waiting 5 minutes to sync all files in Drive\n"]}],"source":["new_folder = os.path.join(data_path, 'similar_images')\n","# Create the new folder if it doesn't exist\n","os.makedirs(new_folder, exist_ok=True)\n","\n","for file_path in duplicated_paths:\n","    # Get the parent directory of the file\n","    age_folder = file_path.split('/')[-2]\n","    file_name = file_path.split('/')[-1]\n","    # Create the destination folder path\n","    destination_folder_path = os.path.join(new_folder, age_folder)\n","    # Create the destination folder if it doesn't exist\n","    os.makedirs(destination_folder_path, exist_ok=True)\n","    # Create the destination file path\n","    destination_file_path = os.path.join(destination_folder_path, file_name)\n","    # Moving similar files identified in hash method\n","    shutil.move(file_path, destination_file_path)\n","\n","print(\"Waiting 5 minutes to sync all files in Drive\")\n","time.sleep(60*5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1yr0G8DMc80YtZYHArk0lopVFSLlkMp1_"},"executionInfo":{"elapsed":59337,"status":"ok","timestamp":1680923162953,"user":{"displayName":"Miguel Ramos","userId":"13440356191463058801"},"user_tz":-60},"id":"zKLf79Lhmn8Q","outputId":"6b699e30-e400-49a1-8c93-a1c9e656b2c6"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["# Verify the mv files\n","verification = {}\n","for key in duplicated_keys.keys():\n","    verification[key] = [path.replace('facial_age_dataset_unsplit', 'similar_images') for path in duplicated_keys[key]]\n","\n","# Calculate the max size of possible duplicated images\n","images_per_row = max([len(count_keys) for count_keys in verification.values()])\n","\n","# Creating a visual inspection for the hashes\n","create_image_grid_per_group(image_groups=verification, images_per_row=images_per_row, show_class=True)"]},{"cell_type":"markdown","metadata":{"id":"OhCnDW02NLI8"},"source":["## 3.2. Removing less represented classes (>75)\n"]},{"cell_type":"markdown","metadata":{"id":"oucP3nMRXGA7"},"source":["It is important to maintain a balanced dataset while training a Deep Learning model to ensure that model's predictions are not skewed towards any particular classes. In our case, as the classes for the individuals over 75 years of age are not well represented in the dataset, it can lead to a biased model, where the model may not be able to accurately predict the age of individuals in that age group.\n","\n","Moreover, since the dataset is unbalanced, the model may end up giving more weightage to the majority classes, leading to a poorer performance on the minority classes. To avoid such scenario, we will remove the images from the dataset that belong to the poorly represented classes, as removing the images of individuals over 75 years of age will help create a more balanced dataset and improve the model's performance. Once again, we are going to temporarily store the removed files in a separate folder.\n","\n","**Note:** During the early stages of our project, we explored the option of utilizing ImageDataGenerator to address the imbalance in our data set. This involved undersampling the overrepresented classes while oversampling the underrepresented classes through data augmentation. However, we eventually realized that this approach was not a conventional method for handling imbalanced data, as it would result in altered class distributions. Specifically, the larger class would have a wide range of variation, while the smaller class would consist of many similar images with minor affine transforms. As a result, the smaller class would occupy a significantly smaller area in the image space than the majority class. [2]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1680923162954,"user":{"displayName":"Miguel Ramos","userId":"13440356191463058801"},"user_tz":-60},"id":"KresqvKShHmd","outputId":"b2569677-88ca-4ab9-88aa-1c3693786191"},"outputs":[{"name":"stdout","output_type":"stream","text":["['/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/076', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/077', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/078', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/079', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/080', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/081', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/082', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/083', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/084', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/085', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/086', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/087', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/088', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/089', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/090', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/091', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/092', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/093', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/095', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/096', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/099', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/100', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/101', '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/110']\n"]}],"source":["# Create a list of folders path with ages above 75 years old\n","above_75_images_path = []\n","for path in os.walk(dataset_path):\n","    age_class = path[0].split('/')[-1]\n","    if age_class:\n","        if int(age_class) > 75:\n","            above_75_images_path.append(path[0])\n","\n","print(above_75_images_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256220,"status":"ok","timestamp":1680923419156,"user":{"displayName":"Miguel Ramos","userId":"13440356191463058801"},"user_tz":-60},"id":"RtJleE4cjUvy","outputId":"b7776efd-e3d0-44a9-9ecd-7b4ce0a1f056"},"outputs":[{"name":"stdout","output_type":"stream","text":["Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/076 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/076\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/077 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/077\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/078 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/078\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/079 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/079\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/080 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/080\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/081 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/081\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/082 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/082\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/083 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/083\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/084 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/084\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/085 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/085\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/086 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/086\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/087 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/087\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/088 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/088\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/089 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/089\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/090 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/090\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/091 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/091\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/092 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/092\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/093 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/093\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/095 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/095\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/096 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/096\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/099 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/099\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/100 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/100\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/101 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/101\n","Moving folder: /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_unsplit/110 to /content/drive/MyDrive/FacialAgeProject/data/above_75_images/110\n","All folders with age >75 moved!\n","Waiting 5 minutes to sync all files in Drive\n"]}],"source":["for folder_path in above_75_images_path:\n","    # Create the destination folder path\n","    destination_folder = folder_path.replace('facial_age_dataset_unsplit', 'above_75_images')\n","    # Create the destination folder if it doesn't exist\n","    os.makedirs(destination_folder_path, exist_ok=True)\n","    # Moving folders\n","    print(f'Moving folder: {folder_path} to {destination_folder}')\n","    shutil.move(folder_path, destination_folder)\n","print('All folders with age >75 moved!')\n","print(\"Waiting 5 minutes to sync all files in Drive\")\n","time.sleep(60*5)"]},{"cell_type":"markdown","metadata":{"id":"6lAf6jpACq-0"},"source":["## 3.3. Splitting the dataset into a temporary train test and a definitive test set\n","\n","\n","\n","\n","In our subsequent steps, we aim to use the `image_dataset_from_directory()` function [3] to divide our recently cleaned image folder into two separate sets: a temporary training set and a final test set. Afterward, we will utilize the previously defined `save_images()` function to save the respective images for each set into their respective designated folders.\n","\n","It's important to note that we saved both the training set and test set because we plan to further subdivide the temporary training set into our definitive training set and validation set later in the model_handcrafted notebook. The validation set will serve as a crucial tool in assessing and improving our different models using a representative sample that is not directly used for training. Additionally, we store the test set since it will be utilized to evaluate the effectiveness of our ultimate models."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6183,"status":"ok","timestamp":1680923425324,"user":{"displayName":"Miguel Ramos","userId":"13440356191463058801"},"user_tz":-60},"id":"SdTMxtSBClHB","outputId":"f6f0cedd-397b-4d58-ef4c-e26a5a0a3e2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 8823 files belonging to 75 classes.\n","Using 7059 files for training.\n","Using 1764 files for validation.\n"]}],"source":["# Dividing our data into a temp set (it'll be transformed in train and validation set) and test set. \n","# Later on we have to adjust,\n","# as we still didn't perform any division for the test set. But for now this is enough.\n","train_ds, test_ds = image_dataset_from_directory(\n","    dataset_path,\n","    labels='inferred',\n","    label_mode='int',\n","    color_mode='rgb',\n","    batch_size=64,\n","    image_size=(200,200),\n","    shuffle=True,\n","    seed=0,\n","    validation_split=0.2,\n","    subset=\"both\"\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wI5JImFx4PxT"},"outputs":[],"source":["# create directories for train, test and validation datasets\n","!mkdir /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_preprocessed -p;\n","!mkdir /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_preprocessed/train -p;\n","!mkdir /content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_preprocessed/test -p;"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nmOzLWdA4wng"},"outputs":[],"source":["#path to save images in train test and validation datasets\n","test_path = '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_preprocessed/test'\n","train_path = '/content/drive/MyDrive/FacialAgeProject/data/facial_age_dataset_preprocessed/train'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":359367,"status":"ok","timestamp":1680923784979,"user":{"displayName":"Miguel Ramos","userId":"13440356191463058801"},"user_tz":-60},"id":"T3_H3FB3tHMs","outputId":"8d0b3937-6e70-4436-f2e0-0e5c24a48b30"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving images for train\n","Saved 0 images\n","Saved 500 images\n","Saved 1000 images\n","Saved 1500 images\n","Saved 2000 images\n","Saved 2500 images\n","Saved 3000 images\n","Saved 3500 images\n","Saved 4000 images\n","Saved 4500 images\n","Saved 5000 images\n","Saved 5500 images\n","Saved 6000 images\n","Saved 6500 images\n","Saved 7000 images\n","Saved all images - Total 7059\n","Saved in 59.238 seconds\n","Waiting 5 minutes to sync all files in Drive\n"]}],"source":["# Save images in temp folder to be splitted in train and validation afterwards\n","save_images(train_ds, output_folder=train_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315594,"status":"ok","timestamp":1680924100557,"user":{"displayName":"Miguel Ramos","userId":"13440356191463058801"},"user_tz":-60},"id":"Tb8MRFbolpFH","outputId":"08888029-a0fc-44b7-c2ca-d0a0847ed42c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving images for test\n","Saved 0 images\n","Saved 500 images\n","Saved 1000 images\n","Saved 1500 images\n","Saved all images - Total 1764\n","Saved in 15.580 seconds\n","Waiting 5 minutes to sync all files in Drive\n"]}],"source":["# Save images in test folder\n","save_images(test_ds, output_folder=test_path)"]},{"cell_type":"markdown","metadata":{"id":"cxT77xNimpjv"},"source":["# 4. Conclusion\n"]},{"cell_type":"markdown","metadata":{"id":"jvNaLmahmsin"},"source":["In conclusion, preprocessing is a crucial aspect of computer vision projects as it enhances image quality and makes it appropriate for training deep learning models. Throught this notebook, we performed the following actions:\n","\n","*   Removed all the duplicates identified by the ahash method, some of which also appear in groups of three and four. Stored the removed images in a separate folder.\n","\n","*   During our investigation, we identified that our dataset was unbalanced, and so we removed the poorly represented classes from our dataset. Stored the removed images in a separate folder.\n","\n","*   We divided our cleaned image folder into a temporary training set and a final test set, and stored the corresponding images in designated folders.\n","\n","Another possible step that we explored briefly that could enhance the quality of our dataset was to remove outliers. However, due to time constraints and the absence of an optimal and satisfactory method, we ultimately decided against removing outliers.\n","\n","In the upcoming model_handcrafted notebook, we plan to subdivide our temporary training set into a definitive training set and a validation set. We will then begin experimenting and handcrafting multiple CNN models."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
